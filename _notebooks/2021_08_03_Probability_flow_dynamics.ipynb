{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-08-03-Probability_flow_dynamics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BOvKZZytGbu"
      },
      "source": [
        "# Probability flow dynamics for constraining stochastic nonlinear systems: A detailed tour\n",
        "> Detailed description of Deterministic Particle Flow control of (upcoming paper) on controling stochastic nonlinear systems by deterministacally perturbing their dynamics.\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [jupyter]\n",
        "- image: images/landscape_r.png\n",
        "- hide: false\n",
        "- search_exclude: false\n",
        "- metadata_key1: particles\n",
        "- metadata_key2: stochastic_control\n",
        "- metadata_key3: probability_flow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FZk2LAqwYs-"
      },
      "source": [
        "#!pip install jupyter_contrib_nbextensions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq7OZ4buwjvM"
      },
      "source": [
        "## **Dynamics of constrained densities**\n",
        "\n",
        "Biological and physical systems are often subjected to intrinsic or extrinsic noise sources that influence their dynamics. Characteristic examples include molecular reactions and chemical kinetics [CITE](#cite-gillespie2003improved), populations of animal species, biological neurons [CITE](#cite-saarinen2008stochastic), and evolution [CITE](#cite-lande2003stochastic),[CITE](#cite-takahata1975effect).\n",
        " Stochastic differential equations (SDEs) effectively capture the phenomenology of the dynamics of such systems, at different precision scales \n",
        " by both considering deterministic and stochastic forces affecting their state variables $X_t \\in  \\mathcal{R}^d$ following\n",
        "\\begin{equation} \\tag{1}\n",
        "  dX_t = f(X_t,t) dt  + \\sigma dW_t. \n",
        "\\end{equation}\n",
        "\n",
        "In Eq.$(1)$ the drift  $f(\\cdot,\\cdot): \\mathcal{R}^d \\times \\mathcal{R} \\rightarrow \\mathcal{R}^d$ is a smooth typically nonlinear function that captures the deterministic part of the driving forces,\n",
        "while $W$ stands for a k--dimensional ($k\\leq d$) vector of independent Wiener processes acting as\n",
        "white noise sources, representing contributions from unaccounted degrees of freedom, thermal fluctuations, or external perturbations. We denote the noise strength by $\\sigma \\in \\mathcal{R}$[^1], and define the noise covariance as\n",
        "${D =\\sigma ^2}$. In the following we refer to this system as the \\emph{uncontrolled} system. \n",
        "\n",
        "[^1]: For the sake of brevity, we consider here a state independent diffusion, but the formalism easily generalises for a state dependent diffusion $\\sigma(x)$, as outlined in the Appendix.}\n",
        "\n",
        "\n",
        "Under multiple independent realisations, the stochastic nature of Eq.$(1)$ gives rise to an ensemble of trajectories starting from an initial state $X_0=x_0$. This ensemble captures the likely evolution of the considered system at later time points. We may characterise the unfolding of this trajectory ensemble in terms of a probability density $p_t(x)$, whose evolution is governed by the Fokker--Planck equation\n",
        "\n",
        "\\begin{align} \\tag{2}\n",
        "\\frac{\\partial p_t(x)}{\\partial t} \n",
        "&= \\nabla\\cdot \\left[- f(x,t) p_t (x) + \\frac{\\sigma^2}{2} \\nabla p_t(x)\\right]\\\\\n",
        "&= {\\cal{L}}_f^\\dagger p_t(x) , \\tag{3}\n",
        "\\end{align}\n",
        "with initial condition $p_0(x) = \\delta(x-x_0)$, and $\\mathcal{L}_f^\\dagger$ denoting the Fokker--Planck operator. Due to the stochastic nature of the system of Eq.$(1)$, exact pinpointing of its state at some later time point $T$ is in general not possible.\n",
        "\n",
        "\n",
        "Yet, often, we desire to drive biophysical and biochemical stochastic processes to predefined target states within a specified time interval.\n",
        "Characteristic examples include designing artificial selection strategies for population dynamics [cite](#cite-nourmohammad2021optimal), or triggering phenotype switches during cell fate determination [cite](#cite-wells2015control). Similar needs for manipulation are also relevant for non-biological, but rather technical systems, e.g. for control of robotic or artificial limbs [cite](#cite-todorov2005stochastic), [cite](#cite-todorov2004optimality). In all these settings, external system interventions become essential. \n",
        "\n",
        "\n",
        "Here, we are interested in introducing constraints $\\mathcal{C}$ to the dynamics of the system of Eq.($1$) acting within a predefined time interval ${0 \\leq t \\leq T}$. The set of possible constraints $\\mathcal{C}$ comprises terminal $\\chi(X_T)$, and/or path constraints $U(x,t),\\text{for } t\\leq T $, depending on whether the desired limiting conditions apply for the entire interval or only to the terminal time point.\n",
        "The path constraints $U(x,t): \\mathcal{R}^{d}\\times \\mathcal{R} \\rightarrow \\mathcal{R} $ penalise specific trajectories (_paths_) to render specific regions of the state space more (un)likely to be visited, while the function $\\chi(x): \\mathcal{R}^{d} \\rightarrow \\mathcal{R}$ influences the terminal system state $X_T$.\n",
        "\n",
        "To incorporate the constraints $\\mathcal{C}$ into the system, we define a modified dynamics, the _controlled_ dynamics, \n",
        "through a change of probability measure of the path ensemble $\\mathbb{P}_f$ induced by the uncontrolled system.\n",
        "More precisely, we consider the path measure\n",
        "$\\mathbb{Q}$ \n",
        " (Appendix A), induced by the controlled system, as equivalent to a _reweighting_ of paths\n",
        "$X_{0:T}$ generated from the uncontrolled dynamics (Eq.$(1)$) over the time interval $[0,\\; T]$. \n",
        "Individual path weights are thus given by the likelihood ratio (_Radon--Nikodym derivative_)\n",
        "\\begin{equation}\n",
        "\\frac{d\\mathbb{Q}}{d\\mathbb{P}_f} (X_{0:T}) = \\frac{\\chi(X_T)}{Z} \\exp\\left[- \\int_0^T U(X_t,t) dt \\right], \\tag{4}\n",
        "\\end{equation}\n",
        "where $Z$ denotes the normalising constant \n",
        "\\begin{equation}\n",
        "Z = \\Bigg \\langle \\chi(X_T) \\exp\\left(- \\int_0^T U(X_t,t) dt \\right) \\Bigg\\rangle_{\\mathbb{P}_f},\n",
        "\\end{equation}\n",
        "and $\\langle \\cdot \\rangle_{\\mathbb{P}_f}$ denotes the expectation over paths of the uncontrolled system.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "According to the Girsanov's theorem, the controlled process defined by the weights of Eq.$(4)$ is also a diffusion process with the same diffusion constant $\\sigma$, but with a modified, time-dependent drift function $g(x,t): \\mathcal{R}^d \\times \\mathcal{R} \\rightarrow \\mathcal{R}^d$ [cite](#cite-girsanov1960transforming), [cite](#cite-oksendal2003stochastic).\n",
        "Thus, we express the controlled dynamics as a time- and state- dependent perturbation $u(x,t): \\mathcal{R}^d \\times \\mathcal{R} \\rightarrow \\mathcal{R}^d$ of the deterministic forces $f(x,t)$ acting on the system \n",
        " \\begin{align} \n",
        "     dX_t &= \\Big( f(X_t,t)   + u(X_t,t) \\Big) \\; dt + \\sigma dW_t \\tag{5} \\\\ &= \\hspace{25pt}g(X_t,t)\\;\\hspace{5pt} dt \\hspace{30pt}+ \\sigma dW_t.\n",
        " \\end{align}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Our goal is to identify the _optimal_ time- and state-dependent interventions $u(x,t)$ that minimise _intervention costs_ and _path constraints_ captured by the cost function\n",
        "\\begin{equation}\n",
        "    S(x,u,t) =  \\frac{1}{2} u(x,t)^T H u(x,t)+ U(x,t),\n",
        "\\end{equation}\n",
        "while also drive the system towards a predefined target state $x^*$ by time $T$, if a terminal constraint is pertinent.\n",
        "The first part of the cost function penalises large intervention values $u(x,t)$, with $H \\in \\mathcal{R}^{d \\times d}$ determining the cost of intervention along each system dimension, whereas the path cost $U(x,t)$ constrains the transient behaviour of the system.\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "Solutions of this type of _stochastic control problems_ rest on the Bellman's principle of optimality, according to which an optimal solution over an interval $[0,\\;T]$ consists of optimal sub-solutions over the respective sub-intervals $[t',\\;T]$ with later starting times $t'$,  and appropriate initial conditions [cite](bellman1956dynamic). This sequence of sub-problems with interdependent initial conditions requires the cost function $S(x,u,t)$ to be minimized over the entire time interval $[0,\\;T]$. Therefore, here, we minimize the _total expected cost_ in that interval defined as the sum of the terminal cost $\\chi(X_T)$ and the time integrated path and intervention costs\n",
        "\\begin{equation}\n",
        " J(x,t=0) = \\min_{u} \\Big\\langle  \\int_{t=0}^T S(x,u,t') \\,  dt' -  \\ln \\chi(X_T) \\Big\\rangle_{\\mathbb{Q}}. \\tag{6}\n",
        "\\end{equation}\n",
        "In Eq.$(6)$, the brackets $\\langle \\cdot \\rangle_{\\mathbb{Q}}$ denote the expectation over the entire path probability measure $\\mathbb{Q}$.\n",
        "\n",
        "\n",
        "To establish the optimality of the interventions, we demand the cost functional $J(x,t)$ to follow the Hamilton--Jacobi--Bellman (_HJB_) equation (Appendix), \n",
        "\\begin{align} \\tag{7}\n",
        "    -\\frac{\\partial}{\\partial t} J(X_t,t) &= \\min_u \\Bigg[ \\frac{1}{2} u^T(X_t) H u(X_t) + U(X_t,t)\\\\ &+ g(X_t,t) \\nabla_x J(X_t,t) + \\frac{1}{2} \\text{Tr}[D \\frac{\\partial^2}{\\partial x^2} J(X_t,t)]  \\Bigg], \\nonumber\n",
        "\\end{align}\n",
        "a second-order _nonlinear_ partial differential equation (_PDE_) with a terminal condition $J(x,T)= \\ln \\chi(X_T)$, which is, therefore, solved backwards in time. \n",
        "The gradient of the solution of this equation\n",
        "\\begin{equation}\n",
        "    u^*(x,t) = - H^{-1}  \\nabla J(x,t),\n",
        "\\end{equation}\n",
        "provides the optimal state- and time-dependent interventions for the considered system with constraints $\\mathcal{C}$. Yet,  without investigating the structure of the solution, direct solving a second-order nonlinear PDE requires computationally demanding calculations, that grow exponentially with increasing system dimension.\n",
        "\n",
        "To simplify matters, we linearise the Hamilton--Jacobi--Bellman equation by employing a logarithmic variable transformation, $J(x,t) = - \\log( \\phi(x,t))$, proposed initially by Nelson in [cite](#cite-nelson2020dynamical), and introduced in the context of stochastic control by Fleming in [cite](fleming1977exit) (_Hopf-Cole transform_). This requires the minimal assumption of the control costs $H$ and noise covariance $D$ being inversely proportional along each state dimension, $H \\propto D^{-1}=\\sigma^{-2}$, known in the literature as the _path integral control condition_ [cite](#cite-kappen2005linear).\n",
        "\n",
        "\n",
        "\n",
        "The logarithmic variable transformation allows us to express the resulting controlled drift \n",
        "\\begin{equation} \n",
        "g(x,t)  = f(x,t) +  \\sigma^2 \\nabla \\ln \\phi(x,t), \n",
        "\\tag{8}\n",
        "\\end{equation}\n",
        "in terms of the solution $\\phi_t(x) \\doteq\\phi(x,t) $ of a _linear_ backward partial differential equation \n",
        "\\begin{equation}\n",
        "\\frac{\\partial \\phi_t(x)}{\\partial t} + {\\cal{L}}_f \\phi_t(x) - U(x,t) \\phi_t(x) = 0 ,\n",
        "\\tag{9}\n",
        "\\end{equation}\n",
        "with terminal condition $\\phi_T(x) = \\chi(X_T) $, and with $\\mathcal{L}_f$ denoting the\n",
        "adjoint Fokker--Planck operator (Appendix)."
      ]
    }
  ]
}