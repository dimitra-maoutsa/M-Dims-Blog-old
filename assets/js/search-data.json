{
  
    
        "post0": {
            "title": "From PDEs to gradient flows for deterministic particle dynamics",
            "content": "We consider PDEs that describe the evolution of a density $ rho_t(x)$ that evolves in time, with $x in mathcal{R}^D$. We describe the temporal evolution of the density $ rho_t(x)$, e.g., a density of particles at location $x$. One fundamental equation is the continuity equation, which prescribes how the the density $ rho_t(x)$ evolves in time according to laws of mass conservation. In particular, the continuity equation declares that the time derivative of the density $ rho_t(x)$ plus some velocity field $v$ begin{equation} partial_t rho_t(x) + nabla cdot left( v(x,t) rho_t(x) right) = 0, end{equation} given some initial condition $ rho_0(x) = rho^0(x)$. The velocity field in this equation prescribes spatial transformation of the density as time evolves, i.e., how a density of particles starting from $ rho^0(x)$ moves according to the velocity field $v(x,t)$. . The continuity equation admits a useful discretisation in terms of particles. We can consider an associated ordinary differential equation. We can consider the evolution of $N$ particles in the Euclidean space, evolving according to the ODE begin{equation} frac{dX_i(t)}{dt} = v(X_i(t),t) , end{equation} given some initial conditions $X_i(0)$. There is a close correspondence between this system of ODEs (the particles) and the solutions of the PDE. In particular, if the velocity field is sufficiently nice (globally Lipschitz in space) , then as long as the iniital conditions of the particles are drawn from the density representing the initial condition of the PDE, i.e. if I take the empirical measure at each of these locations, i.e., begin{equation} hat{ rho}_0 = frac{1}{N} sum^N_{i=1} delta(x-X_i(0)) xrightarrow{N rightarrow infty} rho_0(x), end{equation} then the evolving locations of these Dirac masses converges according to the Wasserstein metric to the continuum solution of the PDE, begin{equation} hat{ rho}_t = frac{1}{N} sum^N_{i=1} delta(x-X_i(t)) xrightarrow{N rightarrow infty} rho_t(x), end{equation} . Because of this close connection between the PDEs and the particle representation a lot of PDEs have a natural discretisation in terms of particles. The PDE conserves mass, i.e. whatever the integral of the initial data is that integral will be preserved over time. Also particle representation preserves positivity. . In general this equation is emph{not} a Wasserstein gradient flow for an arbitrary velocity field. . The difference between the transient empirical solution $ hat{ rho}_t$ and the exact solution $ rho_t$ within the time interval $t in[0,T]$ will be bounded by a constant weighted by the initial distance of the initial condition . begin{equation} mathcal{W}_2( hat{ rho}_t, rho_t) leq C_{T, | nabla v |_{ infty}} mathcal{W}_2( hat{ rho}_0, rho_0) end{equation}Fokker Planck equations as gradient flows . An equation that is a Wasserstein gradient flow and has attracted a lot of interest in the last years is the Fokker-Planck equation. It describes the evolution of a density according to adrift term begin{equation} partial_t rho_t(x) = nabla cdot left( nabla V rho_t(x) right) + nabla nabla rho_t(x). end{equation} This has an associated particle method, a stochastic one, because we have the diffusion present begin{equation} dX_t = -V(X_t)dt + sqrt{2} dW_t end{equation} The empirical measure represented in terms of particles will converge almost surely to the solution of the PDE. . This PDE has a corresponding particle discretisation. Each particle evolves according to this Ordinary differential equation. . Since the density interacts with itself, the particles interact with each other through the second term. . This equation has a Wasserstein gradient flow structure. It is the gradient flow of this energy begin{equation} mathcal{E}( rho) = int V(x) rho(x) dx + int rho(x) log rho(x) dx end{equation} it has an external potential term, and the second term is the negative entropy. The particles are going at a direction negative of the gradient of the energy landscape for conservative systems, where the potential is small, to make the energy smaller. The diffusion term forces the density to spread out, so this term makes the entropy smaller. . Fokker-Planck equation can be viewed as a gradient flow. The central point of this idea is to define a manifold on which the Fokker-Planck system is a dynamical system on the manifold and evolving according to its gradient. . By understanding convexity properties of the function V that represents the potential can inform us about convexity properties of the energy landscape, and from there we can recover properties of the Fokker-Planck equation, i.e. contraction of solutions, exponential convergence to the equilibrium, etc. . The particle solution is not an Wasserstein gradient flow of this energy. The reason for this is that I could write the PDE as a continuity type of equation begin{equation} partial_t rho_t(x) = nabla cdot left[ underbrace{( nabla V + frac{ nabla rho}{ rho})}_{ text{velocity field:} v(x,t)} rho right] end{equation} But this is a weird velocity field and for a general density the particle method will not be well defined. Due to the diffusion the instantaneous Dirac masses will not remain Dirac masses. . The Wasserstein space is the space of probability measures on $ mathcal{R}^N$ with the metric induced by the Wasserstein distance. . The seminal work of Jordan-Kinderlehrer-Otto~[jordan1998variational] established the view of the Fokker--Planck equation as a gradient flow of the Kullback Leibler divergence functional on a probability space equipped with a Wasserstein metric. The solution of the Fokker--Planck equation with drift forces arising as a gradient of a potential $V(x)$, i.e., $f(x)= nabla V(x)$ was identified as the gradient flow of the free energy with respect to the Wasserstein metric. For a gradient system, the free energy difference between two states $ delta F$ amounts to the negative entropy production times the temperature $ delta F = - mathcal{T} mathcal{S}$, where $ mathcal{S}$ stands for the entropy production. Thus this formulation may be viewed as a maximum entropy principle for the Fokker Planck. . The Fokker-Planck equation can be viewed as as the gradient flow in the Wasserstein metric of the relative entropy functional begin{equation} S( rho) = int_{ mathcal{R}^d} rho(x) log left( frac{ rho(x)}{e^{-V(x)}} right)dx. end{equation} . Major computational challenge of the jko scheme is how to computationally efficiently compute the optimal trnasport cost. . The optimal transport yields geodesics in the Wasserstein space [cite Villani old and new]. The evolution of the probability density described by the Fokker--Planck equation amounts to the a curve in the Wasserstein space, the actual length of this curve is identified as the distance between the initial and the terminal points if this curve is a geodesic. All other curves the connect the two measures have larger dissipation. Optimal transport protocols correspond to geodesics in the Wasserstein space and can be employed in an equivalent definition of curvature. .",
            "url": "https://dimitra-maoutsa.github.io/M-Dims-Blog/jupyter/2025/04/26/_11_02-From_PDEs_to_gradient_flows.html",
            "relUrl": "/jupyter/2025/04/26/_11_02-From_PDEs_to_gradient_flows.html",
            "date": " • Apr 26, 2025"
        }
        
    
  
    
        ,"post1": {
            "title": "Probability flow dynamics for constraining stochastic nonlinear systems",
            "content": "Dynamics of constrained densities . Biological and physical systems are often subjected to intrinsic or extrinsic noise sources that influence their dynamics. Characteristic examples include molecular reactions and chemical kinetics CITE, populations of animal species, biological neurons CITE, and evolution CITE,CITE. Stochastic differential equations (SDEs) effectively capture the phenomenology of the dynamics of such systems, at different precision scales by both considering deterministic and stochastic forces affecting their state variables $X_t in mathcal{R}^d$ following . $$dX_t = f(X_t,t) dt + sigma dW_t. $$ . In Eq.$(1)$ the drift $f( cdot, cdot): mathcal{R}^d times mathcal{R} rightarrow mathcal{R}^d$ is a smooth typically nonlinear function that captures the deterministic part of the driving forces, while $W$ stands for a k--dimensional ($k leq d$) vector of independent Wiener processes acting as white noise sources, representing contributions from unaccounted degrees of freedom, thermal fluctuations, or external perturbations. We denote the noise strength by $ sigma in mathcal{R}$1, and define the noise covariance as ${D = sigma ^2}$. In the following we refer to this system as the emph{uncontrolled} system. . Under multiple independent realisations, the stochastic nature of Eq.$(1)$ gives rise to an ensemble of trajectories starting from an initial state $X_0=x_0$. This ensemble captures the likely evolution of the considered system at later time points. We may characterise the unfolding of this trajectory ensemble in terms of a probability density $p_t(x)$, whose evolution is governed by the Fokker--Planck equation . $$ frac{ partial p_t(x)}{ partial t} = nabla cdot left[- f(x,t) p_t (x) + frac{ sigma^2}{2} nabla p_t(x) right]$$ $$ hspace{-57pt}= { cal{L}}_f^ dagger p_t(x) ,$$ . with initial condition $p_0(x) = delta(x-x_0)$, and $ mathcal{L}_f^ dagger$ denoting the Fokker--Planck operator. Due to the stochastic nature of the system of Eq.$(1)$, exact pinpointing of its state at some later time point $T$ is in general not possible. . Yet, often, we desire to drive biophysical and biochemical stochastic processes to predefined target states within a specified time interval. Characteristic examples include designing artificial selection strategies for population dynamics cite, or triggering phenotype switches during cell fate determination cite. Similar needs for manipulation are also relevant for non-biological, but rather technical systems, e.g. for control of robotic or artificial limbs cite, cite. In all these settings, external system interventions become essential. . Here, we are interested in introducing constraints $ mathcal{C}$ to the dynamics of the system of Eq.($1$) acting within a predefined time interval ${0 leq t leq T}$. The set of possible constraints $ mathcal{C}$ comprises terminal $ chi(X_T)$, and/or path constraints $U(x,t), text{for } t leq T $, depending on whether the desired limiting conditions apply for the entire interval or only to the terminal time point. The path constraints $U(x,t): mathcal{R}^{d} times mathcal{R} rightarrow mathcal{R} $ penalise specific trajectories (paths) to render specific regions of the state space more (un)likely to be visited, while the function $ chi(x): mathcal{R}^{d} rightarrow mathcal{R}$ influences the terminal system state $X_T$. . To incorporate the constraints $ mathcal{C}$ into the system, we define a modified dynamics, the controlled dynamics, through a change of probability measure of the path ensemble $ mathbb{P}_f$ induced by the uncontrolled system. More precisely, we consider the path measure $ mathbb{Q}$ (Appendix A), induced by the controlled system, as equivalent to a reweighting of paths $X_{0:T}$ generated from the uncontrolled dynamics (Eq.$(1)$) over the time interval $[0, ; T]$. Individual path weights are thus given by the likelihood ratio (Radon--Nikodym derivative) . $$ frac{d mathbb{Q}}{d mathbb{P}_f} (X_{0:T}) = frac{ chi(X_T)}{Z} exp left[- int_0^T U(X_t,t) dt right],$$ . where $Z$ denotes the normalising constant . $$Z = Bigg langle chi(X_T) exp left(- int_0^T U(X_t,t) dt right) Bigg rangle_{ mathbb{P}_f},$$ . and $ langle cdot rangle_{ mathbb{P}_f}$ denotes the expectation over paths of the uncontrolled system. . According to the Girsanov&#39;s theorem, the controlled process defined by the weights of Eq.$(4)$ is also a diffusion process with the same diffusion constant $ sigma$, but with a modified, time-dependent drift function $g(x,t): mathcal{R}^d times mathcal{R} rightarrow mathcal{R}^d$ cite, cite. Thus, we express the controlled dynamics as a time- and state- dependent perturbation $u(x,t): mathcal{R}^d times mathcal{R} rightarrow mathcal{R}^d$ of the deterministic forces $f(x,t)$ acting on the system . $$ dX_t = Big( f(X_t,t) + u(X_t,t) Big) ; dt + sigma dW_t $$ $$= hspace{25pt}g(X_t,t) ; hspace{5pt} dt hspace{30pt}+ sigma dW_t.$$ . Our goal is to identify the optimal time- and state-dependent interventions $u(x,t)$ that minimise intervention costs and path constraints captured by the cost function . $$S(x,u,t) = frac{1}{2} u(x,t)^T H u(x,t)+ U(x,t),$$ . while also drive the system towards a predefined target state $x^*$ by time $T$, if a terminal constraint is pertinent. The first part of the cost function penalises large intervention values $u(x,t)$, with $H in mathcal{R}^{d times d}$ determining the cost of intervention along each system dimension, whereas the path cost $U(x,t)$ constrains the transient behaviour of the system. . Solutions of this type of stochastic control problems rest on the Bellman&#39;s principle of optimality, according to which an optimal solution over an interval $[0, ;T]$ consists of optimal sub-solutions over the respective sub-intervals $[t&#39;, ;T]$ with later starting times $t&#39;$, and appropriate initial conditions cite. This sequence of sub-problems with interdependent initial conditions requires the cost function $S(x,u,t)$ to be minimized over the entire time interval $[0, ;T]$. Therefore, here, we minimize the total expected cost in that interval defined as the sum of the terminal cost $ chi(X_T)$ and the time integrated path and intervention costs . $$ J(x,t=0) = min_{u} Big langle int_{t=0}^T S(x,u,t&#39;) , dt&#39; - ln chi(X_T) Big rangle_{ mathbb{Q}}. $$ In Eq.$(6)$, the brackets $ langle cdot rangle_{ mathbb{Q}}$ denote the expectation over the entire path probability measure $ mathbb{Q}$. . To establish the optimality of the interventions, we demand the cost functional $J(x,t)$ to follow the Hamilton--Jacobi--Bellman (HJB) equation (Appendix), . $$ - frac{ partial}{ partial t} J(X_t,t) = min_u Bigg[ frac{1}{2} u^T(X_t) H u(X_t) + U(X_t,t)$$ $$ hspace{95pt} + g(X_t,t) nabla_x J(X_t,t) + frac{1}{2} text{Tr}[D frac{ partial^2}{ partial x^2} J(X_t,t)] Bigg] $$ a nonlinear partial differential equation (PDE) with a terminal condition $J(x,T)= ln chi(X_T)$, which is, therefore, solved backwards in time. The gradient of the solution of this equation . $$u^*(x,t) = - H^{-1} nabla J(x,t),$$ . provides the optimal state- and time-dependent interventions for the considered system with constraints $ mathcal{C}$. Yet, without investigating the structure of the solution, direct solving a second-order nonlinear PDE requires computationally demanding calculations, that grow exponentially with increasing system dimension. . To simplify matters, we linearise the Hamilton--Jacobi--Bellman equation by employing a logarithmic variable transformation, $J(x,t) = - log( phi(x,t))$, proposed initially by Nelson in cite, and introduced in the context of stochastic control by Fleming in cite (Hopf-Cole transform). This requires the minimal assumption of the control costs $H$ and noise covariance $D$ being inversely proportional along each state dimension, $H propto D^{-1}= sigma^{-2}$, known in the literature as the path integral control condition cite. . The logarithmic variable transformation allows us to express the resulting controlled drift . $$g(x,t) = f(x,t) + sigma^2 nabla ln phi(x,t), $$ . in terms of the solution $ phi_t(x) doteq phi(x,t) $ of a linear backward partial differential equation . $$ frac{ partial phi_t(x)}{ partial t} + { cal{L}}_f phi_t(x) - U(x,t) phi_t(x) = 0 ,$$ . with terminal condition $ phi_T(x) = chi(X_T) $, and with $ mathcal{L}_f$ denoting the adjoint Fokker--Planck operator (Appendix). . . For the sake of brevity, we consider here a state independent diffusion, but the formalism easily generalises for a state dependent diffusion $ sigma(x)$, as outlined in the Appendix.}&#8617; . |",
            "url": "https://dimitra-maoutsa.github.io/M-Dims-Blog/jupyter/2025/04/26/_08_03_Probability_flow_dynamics.html",
            "relUrl": "/jupyter/2025/04/26/_08_03_Probability_flow_dynamics.html",
            "date": " • Apr 26, 2025"
        }
        
    
  
    
        ,"post2": {
            "title": "Probability flow dynamics for constraining stochastic nonlinear systems",
            "content": "Dynamics of constrained densities . Biological and physical systems are often subjected to intrinsic or extrinsic noise sources that influence their dynamics. Characteristic examples include molecular reactions and chemical kinetics CITE, populations of animal species, biological neurons CITE, and evolution CITE,CITE. Stochastic differential equations (SDEs) effectively capture the phenomenology of the dynamics of such systems, at different precision scales by both considering deterministic and stochastic forces affecting their state variables $X_t in mathcal{R}^d$ following . $$dX_t = f(X_t,t) dt + sigma dW_t. $$ . In Eq.$(1)$ the drift $f( cdot, cdot): mathcal{R}^d times mathcal{R} rightarrow mathcal{R}^d$ is a smooth typically nonlinear function that captures the deterministic part of the driving forces, while $W$ stands for a k--dimensional ($k leq d$) vector of independent Wiener processes acting as white noise sources, representing contributions from unaccounted degrees of freedom, thermal fluctuations, or external perturbations. We denote the noise strength by $ sigma in mathcal{R}$1, and define the noise covariance as ${D = sigma ^2}$. In the following we refer to this system as the emph{uncontrolled} system. . Under multiple independent realisations, the stochastic nature of Eq.$(1)$ gives rise to an ensemble of trajectories starting from an initial state $X_0=x_0$. This ensemble captures the likely evolution of the considered system at later time points. We may characterise the unfolding of this trajectory ensemble in terms of a probability density $p_t(x)$, whose evolution is governed by the Fokker--Planck equation . $$ frac{ partial p_t(x)}{ partial t} = nabla cdot left[- f(x,t) p_t (x) + frac{ sigma^2}{2} nabla p_t(x) right]$$ $$ hspace{-57pt}= { cal{L}}_f^ dagger p_t(x) ,$$ . with initial condition $p_0(x) = delta(x-x_0)$, and $ mathcal{L}_f^ dagger$ denoting the Fokker--Planck operator. Due to the stochastic nature of the system of Eq.$(1)$, exact pinpointing of its state at some later time point $T$ is in general not possible. . Yet, often, we desire to drive biophysical and biochemical stochastic processes to predefined target states within a specified time interval. Characteristic examples include designing artificial selection strategies for population dynamics cite, or triggering phenotype switches during cell fate determination cite. Similar needs for manipulation are also relevant for non-biological, but rather technical systems, e.g. for control of robotic or artificial limbs cite, cite. In all these settings, external system interventions become essential. . Here, we are interested in introducing constraints $ mathcal{C}$ to the dynamics of the system of Eq.($1$) acting within a predefined time interval ${0 leq t leq T}$. The set of possible constraints $ mathcal{C}$ comprises terminal $ chi(X_T)$, and/or path constraints $U(x,t), text{for } t leq T $, depending on whether the desired limiting conditions apply for the entire interval or only to the terminal time point. The path constraints $U(x,t): mathcal{R}^{d} times mathcal{R} rightarrow mathcal{R} $ penalise specific trajectories (paths) to render specific regions of the state space more (un)likely to be visited, while the function $ chi(x): mathcal{R}^{d} rightarrow mathcal{R}$ influences the terminal system state $X_T$. . To incorporate the constraints $ mathcal{C}$ into the system, we define a modified dynamics, the controlled dynamics, through a change of probability measure of the path ensemble $ mathbb{P}_f$ induced by the uncontrolled system. More precisely, we consider the path measure $ mathbb{Q}$ (Appendix A), induced by the controlled system, as equivalent to a reweighting of paths $X_{0:T}$ generated from the uncontrolled dynamics (Eq.$(1)$) over the time interval $[0, ; T]$. Individual path weights are thus given by the likelihood ratio (Radon--Nikodym derivative) . $$ frac{d mathbb{Q}}{d mathbb{P}_f} (X_{0:T}) = frac{ chi(X_T)}{Z} exp left[- int_0^T U(X_t,t) dt right],$$ . where $Z$ denotes the normalising constant . $$Z = Bigg langle chi(X_T) exp left(- int_0^T U(X_t,t) dt right) Bigg rangle_{ mathbb{P}_f},$$ . and $ langle cdot rangle_{ mathbb{P}_f}$ denotes the expectation over paths of the uncontrolled system. . According to the Girsanov&#39;s theorem, the controlled process defined by the weights of Eq.$(4)$ is also a diffusion process with the same diffusion constant $ sigma$, but with a modified, time-dependent drift function $g(x,t): mathcal{R}^d times mathcal{R} rightarrow mathcal{R}^d$ cite, cite. Thus, we express the controlled dynamics as a time- and state- dependent perturbation $u(x,t): mathcal{R}^d times mathcal{R} rightarrow mathcal{R}^d$ of the deterministic forces $f(x,t)$ acting on the system . $$ dX_t = Big( f(X_t,t) + u(X_t,t) Big) ; dt + sigma dW_t $$ $$= hspace{25pt}g(X_t,t) ; hspace{5pt} dt hspace{30pt}+ sigma dW_t.$$ . Our goal is to identify the optimal time- and state-dependent interventions $u(x,t)$ that minimise intervention costs and path constraints captured by the cost function . $$S(x,u,t) = frac{1}{2} u(x,t)^T H u(x,t)+ U(x,t),$$ . while also drive the system towards a predefined target state $x^*$ by time $T$, if a terminal constraint is pertinent. The first part of the cost function penalises large intervention values $u(x,t)$, with $H in mathcal{R}^{d times d}$ determining the cost of intervention along each system dimension, whereas the path cost $U(x,t)$ constrains the transient behaviour of the system. . Solutions of this type of stochastic control problems rest on the Bellman&#39;s principle of optimality, according to which an optimal solution over an interval $[0, ;T]$ consists of optimal sub-solutions over the respective sub-intervals $[t&#39;, ;T]$ with later starting times $t&#39;$, and appropriate initial conditions cite. This sequence of sub-problems with interdependent initial conditions requires the cost function $S(x,u,t)$ to be minimized over the entire time interval $[0, ;T]$. Therefore, here, we minimize the total expected cost in that interval defined as the sum of the terminal cost $ chi(X_T)$ and the time integrated path and intervention costs . $$ J(x,t=0) = min_{u} Big langle int_{t=0}^T S(x,u,t&#39;) , dt&#39; - ln chi(X_T) Big rangle_{ mathbb{Q}}. $$ In Eq.$(6)$, the brackets $ langle cdot rangle_{ mathbb{Q}}$ denote the expectation over the entire path probability measure $ mathbb{Q}$. . To establish the optimality of the interventions, we demand the cost functional $J(x,t)$ to follow the Hamilton--Jacobi--Bellman (HJB) equation (Appendix), . $$ - frac{ partial}{ partial t} J(X_t,t) = min_u Bigg[ frac{1}{2} u^T(X_t) H u(X_t) + U(X_t,t)$$ $$ hspace{95pt} + g(X_t,t) nabla_x J(X_t,t) + frac{1}{2} text{Tr}[D frac{ partial^2}{ partial x^2} J(X_t,t)] Bigg] $$ a nonlinear partial differential equation (PDE) with a terminal condition $J(x,T)= ln chi(X_T)$, which is, therefore, solved backwards in time. The gradient of the solution of this equation . $$u^*(x,t) = - H^{-1} nabla J(x,t),$$ . provides the optimal state- and time-dependent interventions for the considered system with constraints $ mathcal{C}$. Yet, without investigating the structure of the solution, direct solving a second-order nonlinear PDE requires computationally demanding calculations, that grow exponentially with increasing system dimension. . To simplify matters, we linearise the Hamilton--Jacobi--Bellman equation by employing a logarithmic variable transformation, $J(x,t) = - log( phi(x,t))$, proposed initially by Nelson in cite, and introduced in the context of stochastic control by Fleming in cite (Hopf-Cole transform). This requires the minimal assumption of the control costs $H$ and noise covariance $D$ being inversely proportional along each state dimension, $H propto D^{-1}= sigma^{-2}$, known in the literature as the path integral control condition cite. . The logarithmic variable transformation allows us to express the resulting controlled drift . $$g(x,t) = f(x,t) + sigma^2 nabla ln phi(x,t), $$ . in terms of the solution $ phi_t(x) doteq phi(x,t) $ of a linear backward partial differential equation . $$ frac{ partial phi_t(x)}{ partial t} + { cal{L}}_f phi_t(x) - U(x,t) phi_t(x) = 0 ,$$ . with terminal condition $ phi_T(x) = chi(X_T) $, and with $ mathcal{L}_f$ denoting the adjoint Fokker--Planck operator (Appendix). . . For the sake of brevity, we consider here a state independent diffusion, but the formalism easily generalises for a state dependent diffusion $ sigma(x)$, as outlined in the Appendix.}&#8617; . |",
            "url": "https://dimitra-maoutsa.github.io/M-Dims-Blog/jupyter/2022/08/08/From_PDEs.html",
            "relUrl": "/jupyter/2022/08/08/From_PDEs.html",
            "date": " • Aug 8, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://dimitra-maoutsa.github.io/M-Dims-Blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This blog is maintained by Dimitra Maoutsa, and is powered by fastpages. .",
          "url": "https://dimitra-maoutsa.github.io/M-Dims-Blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  
      ,"page2": {
          "title": "",
          "content": "Posts .",
          "url": "https://dimitra-maoutsa.github.io/M-Dims-Blog/",
          "relUrl": "/",
          "date": ""
      }
      
  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://dimitra-maoutsa.github.io/M-Dims-Blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}