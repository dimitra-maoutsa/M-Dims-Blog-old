<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Probability flow dynamics for constraining stochastic nonlinear systems</h1><p class="page-description">Detailed trying things .</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-08-08T00:00:00-05:00" itemprop="datePublished">
        Aug 8, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/M-Dims-Blog/categories/#jupyter">jupyter</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/dimitra-maoutsa/M-Dims-Blog/tree/master/_notebooks/2022-08-08-From_PDEs.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/M-Dims-Blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/dimitra-maoutsa/M-Dims-Blog/master?filepath=_notebooks%2F2022-08-08-From_PDEs.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/M-Dims-Blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/dimitra-maoutsa/M-Dims-Blog/blob/master/_notebooks/2022-08-08-From_PDEs.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/M-Dims-Blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#probability-flow-dynamics-for-constraining-stochastic-nonlinear-systems">Probability flow dynamics for constraining stochastic nonlinear systems</a>
<ul>
<li class="toc-entry toc-h2"><a href="#Dynamics-of-constrained-densities">
Dynamics of constrained densities 
</a></li>
</ul>
</li>
</ul><article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">
<a class="anchor" href="#probability-flow-dynamics-for-constraining-stochastic-nonlinear-systems" aria-hidden="true"><span class="octicon octicon-link"></span></a>Probability flow dynamics for constraining stochastic nonlinear systems</h1>
<p class="page-description">Detailed trying things .</p>
<p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-08-08T00:00:00-05:00" itemprop="datePublished">
        Aug 8, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i> 
      
        <a class="category-tags-link" href="/M-Dims-Blog/categories/#jupyter">jupyter</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/dimitra-maoutsa/M-Dims-Blog/tree/master/_notebooks/2022-08-08-From_PDEs.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/M-Dims-Blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/dimitra-maoutsa/M-Dims-Blog/master?filepath=_notebooks%2F2022-08-08-From_PDEs.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/M-Dims-Blog/assets/badges/binder.svg" alt="Open In Binder">
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/dimitra-maoutsa/M-Dims-Blog/blob/master/_notebooks/2022-08-08-From_PDEs.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/M-Dims-Blog/assets/badges/colab.svg" alt="Open In Colab">
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Dynamics-of-constrained-densities">Dynamics of constrained densities </a></li>
</ul>
<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-08-08-From_PDEs.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dynamics-of-constrained-densities">
<a class="anchor" href="#Dynamics-of-constrained-densities" aria-hidden="true"><span class="octicon octicon-link"></span></a>
<a class="anchor" href="#Dynamics-of-constrained-densities" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Dynamics of constrained densities</strong><a class="anchor-link" href="#Dynamics-of-constrained-densities"> </a>
</h2>
<p>Biological and physical systems are often subjected to intrinsic or extrinsic noise sources that influence their dynamics. Characteristic examples include molecular reactions and chemical kinetics <a href="#cite-gillespie2003improved">CITE</a>, populations of animal species, biological neurons <a href="#cite-saarinen2008stochastic">CITE</a>, and evolution <a href="#cite-lande2003stochastic">CITE</a>,<a href="#cite-takahata1975effect">CITE</a>.
 Stochastic differential equations (SDEs) effectively capture the phenomenology of the dynamics of such systems, at different precision scales 
 by both considering deterministic and stochastic forces affecting their state variables $X_t \in  \mathcal{R}^d$ following</p>
<p>$$dX_t = f(X_t,t) dt  + \sigma dW_t. $$</p>
<p>In Eq.$(1)$ the drift  $f(\cdot,\cdot): \mathcal{R}^d \times \mathcal{R} \rightarrow \mathcal{R}^d$ is a smooth typically nonlinear function that captures the deterministic part of the driving forces,
while $W$ stands for a k--dimensional ($k\leq d$) vector of independent Wiener processes acting as
white noise sources, representing contributions from unaccounted degrees of freedom, thermal fluctuations, or external perturbations. We denote the noise strength by $\sigma \in \mathcal{R}$<sup class="footnote-ref" id="fnref-1"><a href="#fn-1">1</a></sup>, and define the noise covariance as
${D =\sigma ^2}$. In the following we refer to this system as the \emph{uncontrolled} system.</p>
<p>Under multiple independent realisations, the stochastic nature of Eq.$(1)$ gives rise to an ensemble of trajectories starting from an initial state $X_0=x_0$. This ensemble captures the likely evolution of the considered system at later time points. We may characterise the unfolding of this trajectory ensemble in terms of a probability density $p_t(x)$, whose evolution is governed by the Fokker--Planck equation</p>
$$\frac{\partial p_t(x)}{\partial t} 
= \nabla\cdot \left[- f(x,t) p_t (x) + \frac{\sigma^2}{2} \nabla p_t(x)\right]$$<p>
$$ \hspace{-57pt}= {\cal{L}}_f^\dagger p_t(x) ,$$
</p>
<p>with initial condition $p_0(x) = \delta(x-x_0)$, and $\mathcal{L}_f^\dagger$ denoting the Fokker--Planck operator. Due to the stochastic nature of the system of Eq.$(1)$, exact pinpointing of its state at some later time point $T$ is in general not possible.</p>
<p>Yet, often, we desire to drive biophysical and biochemical stochastic processes to predefined target states within a specified time interval.
Characteristic examples include designing artificial selection strategies for population dynamics <a href="#cite-nourmohammad2021optimal">cite</a>, or triggering phenotype switches during cell fate determination <a href="#cite-wells2015control">cite</a>. Similar needs for manipulation are also relevant for non-biological, but rather technical systems, e.g. for control of robotic or artificial limbs <a href="#cite-todorov2005stochastic">cite</a>, <a href="#cite-todorov2004optimality">cite</a>. In all these settings, external system interventions become essential.</p>
<p>Here, we are interested in introducing constraints $\mathcal{C}$ to the dynamics of the system of Eq.($1$) acting within a predefined time interval ${0 \leq t \leq T}$. The set of possible constraints $\mathcal{C}$ comprises terminal $\chi(X_T)$, and/or path constraints $U(x,t),\text{for } t\leq T $, depending on whether the desired limiting conditions apply for the entire interval or only to the terminal time point.
The path constraints $U(x,t): \mathcal{R}^{d}\times \mathcal{R} \rightarrow \mathcal{R} $ penalise specific trajectories (<em>paths</em>) to render specific regions of the state space more (un)likely to be visited, while the function $\chi(x): \mathcal{R}^{d} \rightarrow \mathcal{R}$ influences the terminal system state $X_T$.</p>
<p>To incorporate the constraints $\mathcal{C}$ into the system, we define a modified dynamics, the <em>controlled</em> dynamics, 
through a change of probability measure of the path ensemble $\mathbb{P}_f$ induced by the uncontrolled system.
More precisely, we consider the path measure
$\mathbb{Q}$ 
 (Appendix A), induced by the controlled system, as equivalent to a <em>reweighting</em> of paths
$X_{0:T}$ generated from the uncontrolled dynamics (Eq.$(1)$) over the time interval $[0,\; T]$. 
Individual path weights are thus given by the likelihood ratio (<em>Radon--Nikodym derivative</em>)</p>
$$\frac{d\mathbb{Q}}{d\mathbb{P}_f} (X_{0:T}) = \frac{\chi(X_T)}{Z} \exp\left[- \int_0^T U(X_t,t) dt \right],$$<p></p>
<p>where $Z$ denotes the normalising constant</p>
<p>
$$Z = \Bigg \langle \chi(X_T) \exp\left(- \int_0^T U(X_t,t) dt \right) \Bigg\rangle_{\mathbb{P}_f},$$
</p>
<p>and $\langle \cdot \rangle_{\mathbb{P}_f}$ denotes the expectation over paths of the uncontrolled system.</p>
<p>According to the Girsanov's theorem, the controlled process defined by the weights of Eq.$(4)$ is also a diffusion process with the same diffusion constant $\sigma$, but with a modified, time-dependent drift function $g(x,t): \mathcal{R}^d \times \mathcal{R} \rightarrow \mathcal{R}^d$ <a href="#cite-girsanov1960transforming">cite</a>, <a href="#cite-oksendal2003stochastic">cite</a>.
Thus, we express the controlled dynamics as a time- and state- dependent perturbation $u(x,t): \mathcal{R}^d \times \mathcal{R} \rightarrow \mathcal{R}^d$ of the deterministic forces $f(x,t)$ acting on the system</p>
<p>
$$ dX_t = \Big( f(X_t,t)   + u(X_t,t) \Big) \; dt + \sigma dW_t $$


$$= \hspace{25pt}g(X_t,t)\;\hspace{5pt} dt \hspace{30pt}+ \sigma dW_t.$$
</p>
<p>Our goal is to identify the <em>optimal</em> time- and state-dependent interventions $u(x,t)$ that minimise <em>intervention costs</em> and <em>path constraints</em> captured by the cost function</p>
<p>
$$S(x,u,t) =  \frac{1}{2} u(x,t)^T H u(x,t)+ U(x,t),$$
</p>
<p>while also drive the system towards a predefined target state $x^*$ by time $T$, if a terminal constraint is pertinent.
The first part of the cost function penalises large intervention values $u(x,t)$, with $H \in \mathcal{R}^{d \times d}$ determining the cost of intervention along each system dimension, whereas the path cost $U(x,t)$ constrains the transient behaviour of the system.</p>
<p>Solutions of this type of <em>stochastic control problems</em> rest on the Bellman's principle of optimality, according to which an optimal solution over an interval $[0,\;T]$ consists of optimal sub-solutions over the respective sub-intervals $[t',\;T]$ with later starting times $t'$,  and appropriate initial conditions <a href="bellman1956dynamic">cite</a>. This sequence of sub-problems with interdependent initial conditions requires the cost function $S(x,u,t)$ to be minimized over the entire time interval $[0,\;T]$. Therefore, here, we minimize the <em>total expected cost</em> in that interval defined as the sum of the terminal cost $\chi(X_T)$ and the time integrated path and intervention costs</p>
<p>
$$ J(x,t=0) = \min_{u} \Big\langle  \int_{t=0}^T S(x,u,t') \,  dt' -  \ln \chi(X_T) \Big\rangle_{\mathbb{Q}}. $$

In Eq.$(6)$, the brackets $\langle \cdot \rangle_{\mathbb{Q}}$ denote the expectation over the entire path probability measure $\mathbb{Q}$.</p>
<p>To establish the optimality of the interventions, we demand the cost functional $J(x,t)$ to follow the Hamilton--Jacobi--Bellman (<em>HJB</em>) equation (Appendix),</p>
<p>$$  -\frac{\partial}{\partial t} J(X_t,t) = \min_u \Bigg[ \frac{1}{2} u^T(X_t) H u(X_t) + U(X_t,t)$$
 $$\hspace{95pt} + g(X_t,t) \nabla_x J(X_t,t) + \frac{1}{2} \text{Tr}[D \frac{\partial^2}{\partial x^2} J(X_t,t)]  \Bigg] $$
a <em>nonlinear</em> partial differential equation (<em>PDE</em>) with a terminal condition $J(x,T)= \ln \chi(X_T)$, which is, therefore, solved backwards in time. 
The gradient of the solution of this equation</p>
<p>$$u^*(x,t) = - H^{-1}  \nabla J(x,t),$$</p>
<p>provides the optimal state- and time-dependent interventions for the considered system with constraints $\mathcal{C}$. Yet,  without investigating the structure of the solution, direct solving a second-order nonlinear PDE requires computationally demanding calculations, that grow exponentially with increasing system dimension.</p>
<p>To simplify matters, we linearise the Hamilton--Jacobi--Bellman equation by employing a logarithmic variable transformation, $J(x,t) = - \log( \phi(x,t))$, proposed initially by Nelson in <a href="#cite-nelson2020dynamical">cite</a>, and introduced in the context of stochastic control by Fleming in <a href="fleming1977exit">cite</a> (<em>Hopf-Cole transform</em>). This requires the minimal assumption of the control costs $H$ and noise covariance $D$ being inversely proportional along each state dimension, $H \propto D^{-1}=\sigma^{-2}$, known in the literature as the <em>path integral control condition</em> <a href="#cite-kappen2005linear">cite</a>.</p>
<p>The logarithmic variable transformation allows us to express the resulting controlled drift</p>
<p>
$$g(x,t)  = f(x,t) +  \sigma^2 \nabla \ln \phi(x,t), $$
</p>
<p>in terms of the solution $\phi_t(x) \doteq\phi(x,t) $ of a <em>linear</em> backward partial differential equation</p>
<p>
$$\frac{\partial \phi_t(x)}{\partial t} + {\cal{L}}_f \phi_t(x) - U(x,t) \phi_t(x) = 0 ,$$
</p>
<p>with terminal condition $\phi_T(x) = \chi(X_T) $, and with $\mathcal{L}_f$ denoting the
adjoint Fokker--Planck operator (Appendix).</p>
<div class="footnotes">
<hr>
<ol>
<li id="fn-1"><p>For the sake of brevity, we consider here a state independent diffusion, but the formalism easily generalises for a state dependent diffusion $\sigma(x)$, as outlined in the Appendix.}<a href="#fnref-1" class="footnote">↩</a></p></li>
</ol>
</div>

</div>
</div>
</div>
</div>



  </div>
<!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js" repo="dimitra-maoutsa/M-Dims-Blog" issue-term="title" label="blogpost-comment" theme="github-light" crossorigin="anonymous" async>
</script><a class="u-url" href="/M-Dims-Blog/jupyter/2022/08/08/From_PDEs.html" hidden></a>
</article>
  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="dimitra-maoutsa/M-Dims-Blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/M-Dims-Blog/jupyter/2022/08/08/From_PDEs.html" hidden></a>
</article>
